{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3871b7",
   "metadata": {},
   "source": [
    "\n",
    "# Classification Decision Tree\n",
    "We will implement a Classification Decision Tree from scratch in the following problem. Then we will use our model to predict malignant and benign breast cancer. For this purpose, we will use the breast_cancer.csv dataset which you can find more details about it <a href=\"https://www.kaggle.com/datasets/merishnasuwal/breast-cancer-prediction-dataset\"><font face=\"Roboto\">here</font></a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ccdebb27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:30:24.876526Z",
     "start_time": "2022-10-22T21:30:24.439793Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from math import log\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2307c50",
   "metadata": {},
   "source": [
    "\n",
    "## Classification Decision Tree Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "618baebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:30:25.034364Z",
     "start_time": "2022-10-22T21:30:25.021627Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.value is not None:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "71b3b483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:30:25.439792Z",
     "start_time": "2022-10-22T21:30:25.404649Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        self.nodes=[]\n",
    "\n",
    "    def is_splitting_finished(self, depth, num_class_labels, num_samples):\n",
    "        if(depth>=self.max_depth or num_class_labels==1 or num_samples<self.min_samples_split):return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def split(self, X, y, feature, threshold):\n",
    "        left_indexes = X[feature] <= threshold\n",
    "        right_indexes = -left_indexes\n",
    "        X_left = X[left_indexes]\n",
    "        y_left = y[left_indexes]\n",
    "        X_right = X[right_indexes]\n",
    "        y_right = y[right_indexes]\n",
    "\n",
    "        return X_left, X_right, y_left, y_right\n",
    "\n",
    "    def entropy(self, y):\n",
    "        import numpy as np\n",
    "        ent=0\n",
    "    \n",
    "    \n",
    "        P=y.value_counts()/len(y)\n",
    "\n",
    "        for p in P  :\n",
    "            if p>0 :\n",
    "                 ent+=p*log(p)\n",
    "        ent=-ent\n",
    "        return ent\n",
    "\n",
    "\n",
    "    def information_gain(self, X, y, feature, threshold):\n",
    "        X_left, X_right, y_left, y_right = self.split (X,y,feature,threshold)\n",
    "\n",
    "        if(len(y_right)==0 or len(y_left)==0):return 0\n",
    "        H_y = self.entropy(y)\n",
    "\n",
    "        p = len(y_left)/len(y)*self.entropy(y_left)+len(y_right)/len(y)*self.entropy(y_right)\n",
    "        ig=H_y-p\n",
    "        return ig\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_ig=0\n",
    "        features=X.columns\n",
    "        best_f=features[0]\n",
    "        best_t=0\n",
    "        for f in features:\n",
    "            tresholds=X[f].unique()\n",
    "            for t in tresholds:\n",
    "                ig=self.information_gain(X,y,f,t)\n",
    "\n",
    "                if(ig>best_ig):\n",
    "                    best_ig=ig\n",
    "                    best_f=f\n",
    "                    best_t=t\n",
    "\n",
    "        return best_f, best_t\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        if self.is_splitting_finished(depth, len(X.columns), len(X)):\n",
    "            X.columns\n",
    "            return None\n",
    "\n",
    "        best_feature, best_threshold = self.best_split(X, y)\n",
    "\n",
    "        X_left, X_right, y_left, y_right = self.split(X, y, best_feature, best_threshold)\n",
    "\n",
    "        left_node = self.build_tree(X_left, y_left, depth=depth + 1)\n",
    "        right_node = self.build_tree(X_right, y_right, depth=depth + 1)\n",
    "\n",
    "        value = None\n",
    "        if left_node is None or right_node is None:\n",
    "            true_value = len(y[y['diagnosis'] == 1])\n",
    "            false_value = len(y[y['diagnosis'] == 0])\n",
    "            if true_value >= false_value:\n",
    "                value = 1\n",
    "            else:\n",
    "                value = 0\n",
    "        cc=Node(feature=best_feature, threshold=best_threshold, left=left_node, right=right_node, value=value)\n",
    "        self.nodes.append(cc)\n",
    "        return cc\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree = self.root\n",
    "        predicted_value = []\n",
    "        for index in list(X.index):\n",
    "            data = X.loc[index]\n",
    "            current_tree = tree\n",
    "            for depth in range(self.max_depth):\n",
    "                if Node.is_leaf(current_tree):\n",
    "                    predicted_value.append(current_tree.value)\n",
    "                    break\n",
    "                feature = current_tree.feature\n",
    "                threshold = current_tree.threshold\n",
    "                if data[feature] <= threshold:\n",
    "                    current_tree = current_tree.left\n",
    "                if data[feature] > threshold:\n",
    "                    current_tree = current_tree.right\n",
    "\n",
    "        return predicted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2197f0",
   "metadata": {},
   "source": [
    "## Data Prepration\n",
    "We performd a good EDA for data. Then split it into train and validation data. We will then use the validation data to find the best model hyperparameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "da5a4d94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:30:26.199958Z",
     "start_time": "2022-10-22T21:30:26.192910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_pdf = pd.read_csv(\"breast_cancer.csv\")\n",
    "breast_cancer_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "27207399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:30:28.478997Z",
     "start_time": "2022-10-22T21:30:28.476044Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "39ba4c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:30:38.003703Z",
     "start_time": "2022-10-22T21:30:37.996292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212 357]\n",
      "diagnosis\n",
      "1            0.627417\n",
      "0            0.372583\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = breast_cancer_pdf.drop(['diagnosis'],axis=1)\n",
    "import numpy as np\n",
    "y = breast_cancer_pdf[['diagnosis']]\n",
    "print(np.bincount(y['diagnosis']))\n",
    "print(y.value_counts()/len(y))\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a8db940f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis\n",
       "204          1\n",
       "70           0\n",
       "131          0\n",
       "431          1\n",
       "540          1"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd7a92",
   "metadata": {},
   "source": [
    "\n",
    "## Training And Tuning Hyperparameters\n",
    "We need to find the best hyperparameters for our model. Your model must have at least accuracy=0.85 on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "assigned-estate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T21:36:15.733600Z",
     "start_time": "2022-10-22T21:36:15.730426Z"
    }
   },
   "outputs": [],
   "source": [
    "max_depths = [5,6,10,11,12,13]\n",
    "min_samples_splits = [2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "58003410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training set for [min_samples_splits=2-max_depths=5] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=2-max_depths=5] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=3-max_depths=5] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=3-max_depths=5] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=4-max_depths=5] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=4-max_depths=5] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=5-max_depths=5] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=5-max_depths=5] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=2-max_depths=6] =0.9588235294117647\n",
      "accuracy of validation set for [min_samples_splits=2-max_depths=6] =0.9122807017543859\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=3-max_depths=6] =0.9470588235294117\n",
      "accuracy of validation set for [min_samples_splits=3-max_depths=6] =0.9122807017543859\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=4-max_depths=6] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=4-max_depths=6] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=5-max_depths=6] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=5-max_depths=6] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=2-max_depths=10] =0.9764705882352941\n",
      "accuracy of validation set for [min_samples_splits=2-max_depths=10] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=3-max_depths=10] =0.9529411764705882\n",
      "accuracy of validation set for [min_samples_splits=3-max_depths=10] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=4-max_depths=10] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=4-max_depths=10] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=5-max_depths=10] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=5-max_depths=10] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=2-max_depths=11] =0.9764705882352941\n",
      "accuracy of validation set for [min_samples_splits=2-max_depths=11] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=3-max_depths=11] =0.9529411764705882\n",
      "accuracy of validation set for [min_samples_splits=3-max_depths=11] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=4-max_depths=11] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=4-max_depths=11] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=5-max_depths=11] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=5-max_depths=11] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=2-max_depths=12] =0.9764705882352941\n",
      "accuracy of validation set for [min_samples_splits=2-max_depths=12] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=3-max_depths=12] =0.9529411764705882\n",
      "accuracy of validation set for [min_samples_splits=3-max_depths=12] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=4-max_depths=12] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=4-max_depths=12] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=5-max_depths=12] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=5-max_depths=12] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=2-max_depths=13] =0.9764705882352941\n",
      "accuracy of validation set for [min_samples_splits=2-max_depths=13] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=3-max_depths=13] =0.9529411764705882\n",
      "accuracy of validation set for [min_samples_splits=3-max_depths=13] =0.899749373433584\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=4-max_depths=13] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=4-max_depths=13] =0.9047619047619048\n",
      "------------------------------------------------\n",
      "accuracy of training set for [min_samples_splits=5-max_depths=13] =0.9294117647058824\n",
      "accuracy of validation set for [min_samples_splits=5-max_depths=13] =0.9047619047619048\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = None\n",
    "best_min_samples_split = None\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "for max_depth in max_depths:\n",
    "    for min_samples_split in min_samples_splits:\n",
    "        clf = DecisionTree(max_depth, min_samples_split)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_val_pred = clf.predict(x_val)\n",
    "        y_train_pred = clf.predict(x_train)\n",
    "        accuracy = accuracy_score(y_val_pred, y_val)\n",
    "        train_accuracy = accuracy_score(y_train_pred, y_train)\n",
    "        print(f\"accuracy of training set for [min_samples_splits={min_samples_split}-max_depths={max_depth}] ={train_accuracy}\")\n",
    "        print(f\"accuracy of validation set for [min_samples_splits={min_samples_split}-max_depths={max_depth}] ={accuracy}\")\n",
    "        print(\"------------------------------------------------\")\n",
    "        if accuracy >= best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_max_depth = max_depth\n",
    "            best_min_samples_split = min_samples_split\n",
    "            best_model = clf\n",
    "            # for node in clf.nodes:\n",
    "            #     print(node.feature)\n",
    "            #     print(node.threshold)\n",
    "            #     print(node.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "24af216797c7fa3433824f4cc9ec3ca8b08e4b473f051468c9d644f49ea155ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
